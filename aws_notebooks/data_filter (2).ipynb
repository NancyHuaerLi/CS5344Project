{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc74aa6-7baf-4787-8465-3086bb094659",
   "metadata": {
    "execution": {
     "iopub.status.idle": "2022-01-01T00:00:00.0Z",
     "shell.execute_reply": "2022-01-01T00:00:00.0Z",
     "shell.execute_reply.started": "2022-01-01T00:00:00.0Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attach to a cluster to execute a cell."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c68f17-88eb-4ec5-bd89-60b6f44de08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T12:47:49.992774Z",
     "iopub.status.busy": "2023-03-18T12:47:49.992355Z",
     "iopub.status.idle": "2023-03-18T12:47:50.244932Z",
     "shell.execute_reply": "2023-03-18T12:47:50.243806Z",
     "shell.execute_reply.started": "2023-03-18T12:47:49.992740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901d997646b24f8d8a4c8a28ea1dbd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from py4j.protocol import Py4JJavaError\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import explode, col, udf, concat_ws, from_json, lit, array, expr, size\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from pyspark.sql.types import BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de276c49-909b-446b-828d-70e818dc260e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T12:47:50.979786Z",
     "iopub.status.busy": "2023-03-18T12:47:50.979447Z",
     "iopub.status.idle": "2023-03-18T12:47:51.227111Z",
     "shell.execute_reply": "2023-03-18T12:47:51.225840Z",
     "shell.execute_reply.started": "2023-03-18T12:47:50.979746Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd1dca56a1c423db3f6e402d57ac982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_bucket = 's3://cs5344-twitter-project'\n",
    "path = '/{}/*.json.gz'\n",
    "folder_list = ['20220122', '20220123','20220124','20220125', \n",
    "               '20220126', '20220127','20220128', '20220129',\n",
    "               '20220130', '20220131', '20220201', '20220202',\n",
    "               '20220203', '20220204', '20220205', '20220206',\n",
    "               '20220207', '20220208', '20220209', '20220210',\n",
    "               '20220211', '20220212', '20220213', '20220214',\n",
    "               '20220215', '20220224', '20220225', '20220226', '20220228']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d471d21e-31ec-4479-8119-fc410a5bdc6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T12:47:51.753826Z",
     "iopub.status.busy": "2023-03-18T12:47:51.753465Z",
     "iopub.status.idle": "2023-03-18T12:47:52.101244Z",
     "shell.execute_reply": "2023-03-18T12:47:52.096844Z",
     "shell.execute_reply.started": "2023-03-18T12:47:51.753796Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cdf1d2b0cc443d8c474a769078d11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_list = ['nintendo', 'pokemon', 'video game', 'game', 'pokémon legends: arceus', 'pokémon', 'legend of arceus',\n",
    "             'legend arceus', 'legends of arceus', 'pokemon legends: arceus', 'arceus', 'twitch', 'stream']\n",
    "# regex for filter\n",
    "regex_pattern = \"(?i)\" + \"|\".join(test_list)\n",
    "regex_pattern_hashtag = \"(?i)\" + \"|\".join([x.strip(' ') for x in test_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb565c3-9b05-47fe-b464-19d93b1c0e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T12:47:53.610156Z",
     "iopub.status.busy": "2023-03-18T12:47:53.609820Z",
     "iopub.status.idle": "2023-03-18T12:47:53.862586Z",
     "shell.execute_reply": "2023-03-18T12:47:53.860866Z",
     "shell.execute_reply.started": "2023-03-18T12:47:53.610126Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11e3b0fcce740df90937c664d93bfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw = spark.read.json(\"./sample_data/*.json\", allowBackslashEscapingAnyCharacter=True)\n",
    "# raw = spark.read.json(\"./202202*/*.json\", allowBackslashEscapingAnyCharacter=True)\n",
    "def pre_process(folder):\n",
    "    raw = spark.read.json(folder, allowBackslashEscapingAnyCharacter=True)\n",
    "    # twitter json counts\n",
    "    # print(raw.count())\n",
    "    '''\n",
    "        Step 1:\n",
    "        Save all tweets, include original tweets in the dataset and retweeted / quoted tweets\n",
    "\n",
    "        only select necessary columns\n",
    "        can refer to twitter API for better understanding:\n",
    "        https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet\n",
    "    '''\n",
    "\n",
    "    twitter_df = raw.select(\"created_at\", \"id_str\", col(\"user.id_str\").alias(\"user_id_str\"),\n",
    "                            col(\"user.screen_name\").alias(\"user_twitter_handle\"),\n",
    "                            \"in_reply_to_status_id_str\", \"in_reply_to_user_id_str\", \"in_reply_to_screen_name\",\n",
    "                            \"retweeted_status\",\n",
    "                            \"quoted_status\",\n",
    "                            \"text\", col(\"entities.hashtags.text\").alias(\"hashtags\"),\n",
    "                            col(\"quoted_status.created_at\").alias(\"quoted_time\"),\n",
    "                            col(\"quoted_status.id_str\").alias(\"quoted_original_tweet_id_str\"),\n",
    "                            col(\"quoted_status.user.id_str\").alias(\"quoted_original_user_id_str\"),\n",
    "                            col(\"quoted_status.user.screen_name\").alias(\"quoted_original_user_twitter_handle\"),\n",
    "                            col(\"retweeted_status.created_at\").alias(\"retweeted_time\"),\n",
    "                            col(\"retweeted_status.id_str\").alias(\"retweeted_original_tweet_id_str\"),\n",
    "                            col(\"retweeted_status.user.screen_name\").alias(\"retweeted_original_user_twitter_handle\"),\n",
    "                            col(\"retweeted_status.user.id_str\").alias(\"retweeted_original_user_id_str\")\n",
    "                            )\n",
    "\n",
    "    # add all retweeted / quoted original tweet themselves to the twitter df\n",
    "    retweet_rdd = twitter_df.filter(twitter_df.retweeted_status.isNotNull()).select('retweeted_status.*')\n",
    "    quoted_rdd = twitter_df.filter(twitter_df.quoted_status.isNotNull()).select('quoted_status.*')\n",
    "\n",
    "    # select columns\n",
    "    retweet_rdd = retweet_rdd.select(\"created_at\", \"id_str\",\n",
    "                                     col(\"user.id_str\").alias(\"user_id_str\"),\n",
    "                                     col(\"user.screen_name\").alias(\"user_twitter_handle\"),\n",
    "                                     \"in_reply_to_status_id_str\", \"in_reply_to_user_id_str\", \"in_reply_to_screen_name\",\n",
    "                                     # \"quoted_status\",\n",
    "                                     \"text\",\n",
    "                                     col(\"entities.hashtags.text\").alias(\"hashtags\"),\n",
    "                                     col(\"quoted_status.created_at\").alias(\"quoted_time\"),\n",
    "                                     col(\"quoted_status.id_str\").alias(\"quoted_original_tweet_id_str\"),\n",
    "                                     col(\"quoted_status.user.id_str\").alias(\"quoted_original_user_id_str\"),\n",
    "                                     col(\"quoted_status.user.screen_name\").alias(\"quoted_original_user_twitter_handle\")\n",
    "                                     )\n",
    "\n",
    "    quoted_rdd = quoted_rdd.select(\"created_at\", \"id_str\", col(\"user.id_str\").alias(\"user_id_str\"),\n",
    "                                   \"in_reply_to_status_id_str\", \"in_reply_to_user_id_str\", \"in_reply_to_screen_name\",\n",
    "                                   \"text\", col(\"entities.hashtags.text\").alias(\"hashtags\")\n",
    "                                   )\n",
    "    twitter_df = twitter_df.drop(\"retweeted_status\", \"quoted_status\")\n",
    "\n",
    "    # add missing columns to make sure all columns match in the above 3 DFs\n",
    "    for c in retweet_rdd.columns:\n",
    "        if c not in twitter_df.columns:\n",
    "            twitter_df = twitter_df.withColumn(c, lit(None))\n",
    "        if c not in quoted_rdd.columns:\n",
    "            quoted_rdd = quoted_rdd.withColumn(c, lit(None))\n",
    "    for c in quoted_rdd.columns:\n",
    "        if c not in twitter_df.columns:\n",
    "            twitter_df = twitter_df.withColumn(c, lit(None))\n",
    "        if c not in retweet_rdd.columns:\n",
    "            retweet_rdd = retweet_rdd.withColumn(c, lit(None))\n",
    "\n",
    "    for c in twitter_df.columns:\n",
    "        if c not in quoted_rdd.columns:\n",
    "            quoted_rdd = quoted_rdd.withColumn(c, lit(None))\n",
    "        if c not in retweet_rdd.columns:\n",
    "            retweet_rdd = retweet_rdd.withColumn(c, lit(None))\n",
    "\n",
    "    # final twitter DFs\n",
    "    combined_raw = twitter_df.unionByName(retweet_rdd).unionByName(quoted_rdd)\n",
    "    del retweet_rdd\n",
    "    del quoted_rdd\n",
    "    del twitter_df\n",
    "    gc.collect()\n",
    "\n",
    "    # convert hashtag column (array type) to str for regex expression filter\n",
    "    raw_df = combined_raw.withColumn(\"text_hashtag\", concat_ws(\",\", col(\"hashtags\")))\n",
    "\n",
    "    filter_df = raw_df.filter(raw_df.text.rlike(regex_pattern) | raw_df.text_hashtag.rlike(regex_pattern)).distinct()\n",
    "    del raw_df\n",
    "    del combined_raw\n",
    "    gc.collect()\n",
    "    print(\"date \" + folder[2:] + \" # of tweets analyzed: \" + str(filter_df.count()))\n",
    "    return filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c21dff-bf07-494f-a9b6-199a141d9640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T12:47:58.078235Z",
     "iopub.status.busy": "2023-03-18T12:47:58.077786Z",
     "iopub.status.idle": "2023-03-18T13:47:46.963135Z",
     "shell.execute_reply": "2023-03-18T13:47:46.961128Z",
     "shell.execute_reply.started": "2023-03-18T12:47:58.078204Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa9a622a6b54948838735cb1a92a0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date ://cs5344-twitter-project/20220122/*.json.gz # of tweets analyzed: 39213\n",
      "7\n",
      "date ://cs5344-twitter-project/20220123/*.json.gz # of tweets analyzed: 44996\n",
      "25\n",
      "date ://cs5344-twitter-project/20220124/*.json.gz # of tweets analyzed: 47045\n",
      "23\n",
      "date ://cs5344-twitter-project/20220125/*.json.gz # of tweets analyzed: 40003\n",
      "23\n",
      "date ://cs5344-twitter-project/20220126/*.json.gz # of tweets analyzed: 36168\n",
      "23\n",
      "date ://cs5344-twitter-project/20220127/*.json.gz # of tweets analyzed: 38718\n",
      "23\n",
      "date ://cs5344-twitter-project/20220128/*.json.gz # of tweets analyzed: 47934\n",
      "23\n",
      "date ://cs5344-twitter-project/20220129/*.json.gz # of tweets analyzed: 54479\n",
      "23\n",
      "date ://cs5344-twitter-project/20220130/*.json.gz # of tweets analyzed: 49244\n",
      "23\n",
      "date ://cs5344-twitter-project/20220131/*.json.gz # of tweets analyzed: 42603\n",
      "23\n",
      "date ://cs5344-twitter-project/20220201/*.json.gz # of tweets analyzed: 41113\n",
      "23\n",
      "date ://cs5344-twitter-project/20220202/*.json.gz # of tweets analyzed: 38464\n",
      "23\n",
      "date ://cs5344-twitter-project/20220203/*.json.gz # of tweets analyzed: 39036\n",
      "23\n",
      "date ://cs5344-twitter-project/20220204/*.json.gz # of tweets analyzed: 41754\n",
      "23\n",
      "date ://cs5344-twitter-project/20220205/*.json.gz # of tweets analyzed: 38003\n",
      "23\n",
      "date ://cs5344-twitter-project/20220206/*.json.gz # of tweets analyzed: 36649\n",
      "23\n",
      "date ://cs5344-twitter-project/20220207/*.json.gz # of tweets analyzed: 34933\n",
      "23\n",
      "date ://cs5344-twitter-project/20220208/*.json.gz # of tweets analyzed: 40043\n",
      "23\n",
      "date ://cs5344-twitter-project/20220209/*.json.gz # of tweets analyzed: 49452\n",
      "23\n",
      "date ://cs5344-twitter-project/20220210/*.json.gz # of tweets analyzed: 46114\n",
      "23\n",
      "date ://cs5344-twitter-project/20220211/*.json.gz # of tweets analyzed: 38327\n",
      "23\n",
      "date ://cs5344-twitter-project/20220212/*.json.gz # of tweets analyzed: 37238\n",
      "23\n",
      "date ://cs5344-twitter-project/20220213/*.json.gz # of tweets analyzed: 39386\n",
      "23\n",
      "date ://cs5344-twitter-project/20220214/*.json.gz # of tweets analyzed: 44576\n",
      "23\n",
      "date ://cs5344-twitter-project/20220215/*.json.gz # of tweets analyzed: 38571\n",
      "23\n",
      "date ://cs5344-twitter-project/20220224/*.json.gz # of tweets analyzed: 36972\n",
      "23\n",
      "date ://cs5344-twitter-project/20220225/*.json.gz # of tweets analyzed: 37921\n",
      "23\n",
      "date ://cs5344-twitter-project/20220226/*.json.gz # of tweets analyzed: 37612\n",
      "23\n",
      "date ://cs5344-twitter-project/20220228/*.json.gz # of tweets analyzed: 47163\n",
      "23"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "filter_df = None\n",
    "for f in folder_list:\n",
    "    # if folder[0:7] == './20220':\n",
    "    folder = input_bucket + path.format(f)\n",
    "    try:\n",
    "        partial_df = pre_process(folder)\n",
    "        if cnt == 0:\n",
    "            filter_df = partial_df\n",
    "        else:\n",
    "            filter_df = filter_df.unionByName(partial_df)\n",
    "        del partial_df\n",
    "        gc.collect()\n",
    "    except Py4JJavaError:\n",
    "        print(folder+\" failed\")\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f4a6b2-27ae-45c9-9f32-eefc293ab51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:47:46.968214Z",
     "iopub.status.busy": "2023-03-18T13:47:46.967058Z",
     "iopub.status.idle": "2023-03-18T15:30:11.439667Z",
     "shell.execute_reply": "2023-03-18T15:30:11.437927Z",
     "shell.execute_reply.started": "2023-03-18T13:47:46.968169Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2f730a3cf94b9faeb0ecd29f54d172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id name done"
     ]
    }
   ],
   "source": [
    "output_bucket = 's3://cs5344-twitter-project/input/'\n",
    "id_name = filter_df.select('user_id_str', 'user_twitter_handle') \\\n",
    "    .union(filter_df.select('in_reply_to_user_id_str', 'in_reply_to_screen_name')).na.drop().distinct()\n",
    "id_name.write.option(\"header\", True).mode('overwrite').csv(output_bucket+'id_name_dict_aws')\n",
    "print('id name done')\n",
    "del id_name\n",
    "gc.collect()\n",
    "\n",
    "filter_df = filter_df.drop(\"user_twitter_handle\", \"in_reply_to_screen_name\",\n",
    "                           \"quoted_original_user_twitter_handle\", \"retweeted_original_user_twitter_handle\")\n",
    "\n",
    "'''\n",
    "    Step 2:\n",
    "    Find all interacted (reply, retweet, quote) users.\n",
    "    if a user A retweet user B's tweet, there will be a directional edge between A and B, A -> B.\n",
    "'''\n",
    "\n",
    "filter_df = filter_df.withColumn(\"connected_user\",\n",
    "                                 array(filter_df.quoted_original_user_id_str, filter_df.in_reply_to_user_id_str,\n",
    "                                       filter_df.retweeted_original_user_id_str))\n",
    "filter_df = filter_df.withColumn(\"connected_user_clean\", expr('filter(connected_user, x -> x is not null)')).drop(\n",
    "    \"connected_user\")\n",
    "\n",
    "original_df = filter_df.filter(size(filter_df.connected_user_clean) == 0)\n",
    "original_df.toDF().write.mode('overwrite').csv('original_tweet_intermediate')\n",
    "\n",
    "filter_df = filter_df.filter(size(filter_df.connected_user_clean) > 0)\n",
    "\n",
    "# each line make sure have only one user and one connected user\n",
    "rdd = filter_df.withColumn(\"connected_user_single\", explode(filter_df.connected_user_clean)).rdd\n",
    "rdd.toDF().write.mode('overwrite').csv('retweeted_tweet_intermediate')\n",
    "del original_df\n",
    "del filter_df\n",
    "gc.collect()\n",
    "\n",
    "# for each user how many times retweet/replay/quote other tweets\n",
    "user_interact_rdd = rdd.map(lambda x: (x[2], 1))\n",
    "user_interact_rdd = user_interact_rdd.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# each pair of users (A, B), how many times A retweet this person B\n",
    "user_pair_rdd = rdd.map(lambda x: ((x[2], x[15]), 1)).reduceByKey(lambda a, b: a + b)\n",
    "user_pair_rdd = user_pair_rdd.map(lambda x: (x[0][0], x[0][1], x[1]))\n",
    "\n",
    "user_pair_rdd.toDF().write.mode('overwrite').csv(output_bucket+'user_pair_aws') #coalesce(1, shuffle = True).\n",
    "user_interact_rdd.toDF().write.mode('overwrite').csv(output_bucket+'user_interact_aws') #coalesce(1, shuffle = True).\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdf528-63c5-40c6-b55e-f0e9b71f0e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
